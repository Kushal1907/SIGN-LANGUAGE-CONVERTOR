# SIGN-LANGUAGE-CONVERTOR


Requirements
1.	Python 3.x
2.	TensorFlow 1.5
3.	Keras
4.	OpenCV 3.4
5.	h5py
6.	pyttsx3
7.	A good CPU (preferably with a GPU).
8.	Use contrast background for better results
Creating a gesture

First set your hand histogram. You do not need to do it again if you have already done it. But you do need to do it if the lighting conditions change. 
python set_hand_hist.py


•	A window "Set hand histogram" will appear.
•	"Set hand histogram" will have 50 squares (5x10).
•	Put your hand in those squares. Make sure your hand covers all the squares.
•	Press 'c'. 1 other window will appear "Thresh".
•	On pressing 'c' only white patches corresponding to the parts of the image which has your skin color should appear on the "Thresh" window.
•	Make sure all the squares are covered by your hand.
•	In case you are not successful then move your hand a little bit and press 'c' again. Repeat this until you get a good histogram.
•	After you get a good histogram press 's' to save the histogram. All the windows close.

It is on user if he/she want to add even more gestures or replace the existing gestures To create your own gestures or replace the given gestures do the following. On starting executing this program, you will have to enter the gesture number and gesture name/text. Then an OpenCV window called "Capturing gestures" which will appear. In the webcam feed you will see a green window (inside which you will have to do your gesture) and a counter that counts the number of pictures stored.
python create_gestures.py 

Press 'c' when you are ready with your gesture. Capturing gesture will begin after a few seconds. Move your hand a little bit here and there. You can pause capturing by pressing 'c' and resume it by pressing 'c'. Capturing resumes after a few second After the counter reaches 1200 the window will close automatically.
After capturing all the gestures, you can flip the images using
python flip_images.py
1.	When you are done adding new gestures run the load_images.py file once. You do not need to run this file again until and unless you add a new gesture.
python load_images.py


Displaying all gestures
1.	To see all the gestures that are stored in 'gestures/' folder run this command
python display_all_gestures.py


Training a model

So, training can be done with Keras. To train using Keras then use the cnn_keras.py file.
python cnn_keras.py

You do not need to retrain your model every time. In case you added or removed a gesture then you need to retrain it.
Get model reports
1.	To get the classification reports about the model make sure you have test_images and test_labels file which are generated by load_images.py. In case you do not have them run load_images.py file again. Then run this file
python get_model_reports.py
2.	You will get the confusion matrix, f scores, precision and recall for the predictions by the model.
Start the file:
python fun_util.py

Text Mode (Press 't' to go to text mode)
1.	In text mode you can create your own words using fingerspellings or use the predefined gestures.
2.	The text on screen will be converted to speech on removing your hand from the green box
3.	Make sure you keep the same gesture on the green box for 15 frames or else the gesture will not be converted to text.
Calculator Mode (Press 'c' to go to calculator mode)
1.	To confirm a digit, make sure you keep the same gesture for 20 frames. On successful confirmation, the number will appear in the vertical center of the black part of the window.
2.	To confirm a number, make the "best of luck" gesture and keep in the green box for 25 frames. You will get used to the timing :P.
3.	You can have any number of digits for both first number and second number.
4.	Currently there are 10 operators.
5.	During operator selection, 1 means '+', 2 means '-', 3 means '*', 4 means '/', 5 means '%', 6 means '**', 7 means '>>' or right shift operator, 8 means '<<' or left shift operator, 9 means '&' or bitwise AND and 0 means '|' or bitwise OR.
